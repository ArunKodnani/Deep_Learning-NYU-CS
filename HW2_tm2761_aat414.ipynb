{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "### Implementing a CNN using tensorflow on the cifar10 dataset\n",
    "\n",
    "Ajay Thorve\n",
    "\n",
    "Titash Mandal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from scipy.ndimage import imread\n",
    "import glob \n",
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import sys,os\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['imread']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few elements : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'airplane',\n",
       " 1: 'automobile',\n",
       " 2: 'bird',\n",
       " 3: 'cat',\n",
       " 4: 'deer',\n",
       " 5: 'dog',\n",
       " 6: 'frog',\n",
       " 7: 'horse',\n",
       " 8: 'ship',\n",
       " 9: 'truck'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializing the variables\n",
    "labels_path = '/data/labels.txt'\n",
    "sample_path = '/data/sampleSubmission.csv'\n",
    "train_path = '/data/train/'\n",
    "test_path = '/data/test/'\n",
    "\n",
    "#Printing the labels to see what the output labels are\n",
    "labels = pd.read_csv(labels_path,header=None)\n",
    "print(\"First few elements : \")\n",
    "labels= labels.to_dict()\n",
    "labels=labels[0]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Applying Image augmentation techniques</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flipping_Image(X_train):\n",
    "    X_flipped_updown= []\n",
    "    X_flipped_left_right= []\n",
    "    X_contrasted=[]\n",
    "    X_cropped = []\n",
    "    X = tf.placeholder(tf.float32, shape = (32, 32, 3))\n",
    "    \n",
    "    X_flipped= tf.image.flip_up_down(X)\n",
    "    \n",
    "    X_flipped_sides= tf.image.flip_left_right(X)\n",
    "    \n",
    "    contrasting = tf.image.random_brightness(X, max_delta=0.2)\n",
    "#     random_img_cropped = tf.random_crop(X,[24,24,3])\n",
    "#     img_final = tf.image.resize_image_with_crop_or_pad(random_img_cropped,32,32)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for images in X_train:\n",
    "            X_flipped_temp = sess.run(X_flipped,feed_dict={X:images})\n",
    "            X_flipped_updown.append(X_flipped_temp)\n",
    "            \n",
    "            X_flipped_sides_temp = sess.run(X_flipped_sides, feed_dict={X:images})\n",
    "            X_flipped_left_right.append(X_flipped_sides_temp)\n",
    "            \n",
    "            contrasting_temp = sess.run(contrasting,feed_dict={X:images})\n",
    "            X_contrasted.append(contrasting_temp)\n",
    "            \n",
    "#             X_cropped_temp = sess.run(img_final,feed_dict={X:images})\n",
    "#             X_cropped.append(X_cropped_temp)\n",
    "            \n",
    "    X_flipped_updown = np.asarray(X_flipped_updown)\n",
    "    X_flipped_left_right = np.asarray(X_flipped_left_right)\n",
    "    X_contrasted = np.asarray(X_contrasted)\n",
    "    X_cropped = np.asarray(X_cropped)\n",
    "    \n",
    "    return X_flipped_updown,X_flipped_left_right,X_contrasted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Extracting the training examples first</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts each label index in y to vector with one_hot encoding\n",
    "    One-hot encoding converts categorical labels to binary values\n",
    "    \"\"\"\n",
    "\n",
    "    y_one_hot = np.zeros((num_classes, y.shape[0]))\n",
    "    y_one_hot[y, range(y.shape[0])] = 1\n",
    "    print(y_one_hot.shape)\n",
    "    return y_one_hot\n",
    "\n",
    "def get_label(filepath):\n",
    "    \"\"\"\n",
    "    Files are assumed to be labeled as: /path/to/file/999_frog.png\n",
    "    Returns label for a filepath\n",
    "    \"\"\"\n",
    "    tokens = filepath.split('/')\n",
    "    label = tokens[-1].split('_')[1][:-4]\n",
    "    return label\n",
    "\n",
    "#Extracting the samples one by one\n",
    "def get_images(path, image_type):\n",
    "    X_train_list = []\n",
    "    Y_train_list=[]\n",
    "    #The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell, \n",
    "    #although results are returned in arbitrary order. \n",
    "    for filename in glob.glob(path + '/*'+ image_type):\n",
    "        Y_train_list.append(get_label(filename))\n",
    "        im=scipy.misc.imread(filename, mode='RGB')\n",
    "        X_train_list.append(im)\n",
    "    return X_train_list,Y_train_list\n",
    "\n",
    "def get_image_test(path, image_type):\n",
    "    X_test_list = []\n",
    "    x_dict_temp ={}\n",
    "    #The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell, \n",
    "    #although results are returned in arbitrary order. \n",
    "    for filename in glob.glob(path + '/*'+ image_type):\n",
    "        im=scipy.misc.imread(filename, mode='RGB')\n",
    "        y_temp = int(filename.split('/')[3].split('.')[0])\n",
    "        temp_tuple = (y_temp,im)\n",
    "        X_test_list.append(temp_tuple)\n",
    "        X_dict = dict(X_test_list)\n",
    "        x_dict_temp = dict(sorted(X_dict.items()))\n",
    "    return np.array(list(x_dict_temp.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_list,Y_train_list=get_images(train_path, '.png')\n",
    "X_train = np.array(X_train_list)\n",
    "Y_train=np.array(Y_train_list)\n",
    "X_test=get_image_test(test_path, '.png')\n",
    "\n",
    "factor_value=pd.factorize(Y_train,sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcf501352e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcf506cef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying some images along with true labels from train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_images():\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.6, wspace=0.3)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(X_train[i])\n",
    "        \n",
    "        # Name of the true class.\n",
    "        cls_true_name = labels[factor_value[0][i]]\n",
    "        xlabel = \"class: {0}\".format(cls_true_name)\n",
    "        \n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    return\n",
    "# show_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_flipped_updown,X_flipped_left_right,X_contrasted=flipping_Image(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180000, 32, 32, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final = np.concatenate((X_train,X_flipped_updown,X_flipped_left_right,X_contrasted),axis=0)\n",
    "X_train_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extracting the labels for training examples</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 45000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_train=one_hot(factor_value[0]).T\n",
    "Y_train_final = np.concatenate((Y_train,Y_train,Y_train,Y_train),axis=0)\n",
    "\n",
    "#Normalizing the images, creating a validation set and a training set\n",
    "\n",
    "X_train_final_version = X_train_final[0:170000,:,:,:]/255\n",
    "X_validate = X_train_final[170000:,:,:,:]/255\n",
    "X_test=X_test/255\n",
    "Y_train_final_version = Y_train_final[0:170000,:]\n",
    "Y_validate = Y_train_final[170000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X_train (170000, 32, 32, 3)\n",
      "Dimension of Y_train (170000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of X_train\",X_train_final_version.shape)\n",
    "print(\"Dimension of Y_train\",Y_train_final_version.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X_test (5000, 32, 32, 3)\n",
      "Dimension of X_validate (10000, 32, 32, 3)\n",
      "Dimension of Y_validate (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of X_test\",X_test.shape)\n",
    "print(\"Dimension of X_validate\",X_validate.shape)\n",
    "print(\"Dimension of Y_validate\",Y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(m,n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_H0, n_W0, n_C0))\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, n_y))\n",
    "    Istraining = tf.placeholder(tf.bool,shape=None)\n",
    "    return X, Y,Istraining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Intialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "     \n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    #W1 is a dictionary of filters of shapes\n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 2 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [3, 3, 3, 32], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "\n",
    "    W2 = tf.get_variable(\"W2\", [3, 3, 32, 32], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W3 = tf.get_variable(\"W3\", [3, 3, 32, 64], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W4 = tf.get_variable(\"W4\", [3, 3, 64, 64], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2,\n",
    "                  \"W3\": W3,\n",
    "                    \"W4\" :W4 }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, Istraining):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    CON1 = tf.nn.conv2d(X,W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(CON1)\n",
    "    \n",
    "    tf.summary.histogram(\"W1-conv1\",W1)\n",
    "    \n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    CON2 = tf.nn.conv2d(A1,W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(CON2)\n",
    "    \n",
    "    tf.summary.histogram(\"W2-conv2\",W2)\n",
    "    \n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,2,2,1], strides = [1,1,1,1], padding = 'SAME')\n",
    "    D2 = tf.layers.dropout(P2,0.8,training=Istraining)\n",
    "    \n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    CON3 = tf.nn.conv2d(D2,W3, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A3 = tf.nn.relu(CON3)\n",
    "    \n",
    "    tf.summary.histogram(\"W3-conv3\",W3)\n",
    "    \n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    CON4 = tf.nn.conv2d(A3,W4, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A3 = tf.nn.relu(CON4)\n",
    "    \n",
    "    tf.summary.histogram(\"W4-conv4\",W4)\n",
    "    \n",
    "    P3 = tf.nn.max_pool(A3, ksize = [1,2,2,1], strides = [1,1,1,1], padding = 'SAME')\n",
    "    D2 = tf.layers.dropout(P3,0.8,training=Istraining)\n",
    "    \n",
    "    FLAT1 = tf.contrib.layers.flatten(D2)\n",
    "    Z3 = tf.contrib.layers.fully_connected(FLAT1, 512)\n",
    "    Z4 = tf.contrib.layers.fully_connected(Z3, 10,activation_fn=None)\n",
    "    y_pred = tf.nn.softmax(Z4,name=\"y_pred\")\n",
    "    \n",
    "\n",
    "    return Z4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Computing the cost - softmax cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z4, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (10, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    #print(\"Inside compute_cost: Y.shape\",Y.shape,\"Z4.shape\",Z4.shape)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z4, labels = Y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Get batch() - as TF works with input batches, this function helps split input data set into small batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def get_batch(X, y, current_index,batch_size):\n",
    "        \"\"\"\n",
    "        Return minibatch of samples and labels\n",
    "        \n",
    "        :param X, y: samples and corresponding labels\n",
    "        :parma batch_size: minibatch size\n",
    "        :returns: (tuple) X_batch, y_batch\n",
    "        \"\"\"\n",
    "        X_batch,y_batch = X[current_index:current_index+batch_size,], y[current_index:current_index+batch_size]\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tensorflow graph\n",
    "\n",
    "    1. Placeholder variables used for inputting data to the graph.\n",
    "    2. Variables that are going to be optimized so as to make the convolutional network perform better.\n",
    "    3. The mathematical formulas for the convolutional network.\n",
    "    4. A loss measure that can be used to guide the optimization of the variables.\n",
    "    5. An optimization method which updates the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tensorflow session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore or initialize variables\n",
    "\n",
    "Training this neural network may take a long time, especially if you do not have a GPU. We therefore save checkpoints during training so we can continue training at another time (e.g. during the night), and also for performing analysis later without having to train the neural network every time we want to use it.\n",
    "\n",
    "If you want to restart the training of the neural network, you have to delete the checkpoints first.\n",
    "\n",
    "This is the directory used for the checkpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = 'checkpoints_augment/'\n",
    "\n",
    "#create the directory if it does not exist\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the base-filename for the checkpoints, TensorFlow will append the iteration number, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = os.path.join(save_dir, 'cifar10_cnn_augment')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints_augment/cifar10_cnn_augment'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try to restore the latest checkpoint. This may fail and raise an exception e.g. if such a checkpoint does not exist, or if you have changed the TensorFlow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(m, n_H0, n_W0, n_C0,n_y) 170000 32 32 3 10\n"
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "(m, n_H0, n_W0, n_C0) = X_train_final_version.shape             \n",
    "n_y = Y_train_final_version.shape[1]\n",
    "print(\"(m, n_H0, n_W0, n_C0,n_y)\",m, n_H0, n_W0, n_C0,n_y)\n",
    "costs = []                                        # To keep track of the cost\n",
    "\n",
    "# Create Placeholders of the correct shape\n",
    "X, Y,Istraining = create_placeholders(m,n_H0, n_W0, n_C0, n_y)\n",
    "\n",
    "# Initialize parameters\n",
    "parameters = initialize_parameters()\n",
    "\n",
    "# Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "Z3 = forward_propagation(X, parameters,Istraining)\n",
    "\n",
    "# Cost function: Add cost function to tensorflow graph\n",
    "cost = compute_cost(Z3, Y)\n",
    "\n",
    "global_step = tf.Variable(initial_value=0,\n",
    "                          name='global_step', trainable=False)\n",
    "\n",
    "# Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=.001).minimize(cost,global_step=global_step)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start the session to compute the tensorflow graph\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter('output_tb',sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model() - Implements a 3 layer ConvNet in TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train,X_validate,Y_validate, learning_rate = 0.0001,num_epochs = 2, minibatch_size = 100, print_cost = True):\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "\n",
    "    count=0\n",
    "    \n",
    "    num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "    # Do the training loop\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_index=0\n",
    "        count+=1\n",
    "        for each_batch in range(num_minibatches):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            seed = seed + 1\n",
    "            # Select a minibatch\n",
    "            (minibatch_X, minibatch_Y) = get_batch(X_train, Y_train,current_index, 200)\n",
    "    #                 print(\"minibatch_X\",minibatch_X.shape,\"minibatch_Y\",minibatch_Y.shape)\n",
    "            current_index+=100\n",
    "            # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "            i_global,_ , temp_cost = sess.run([global_step,optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y, Istraining: True})\n",
    "\n",
    "            minibatch_cost += temp_cost / num_minibatches\n",
    "            if each_batch%100 == 0:\n",
    "                print('.',end='')\n",
    "\n",
    "    #       Print the cost every epoch\n",
    "        if print_cost == True and epoch % 1 == 0:\n",
    "            \n",
    "            summary_str = sess.run(summaries,feed_dict={X:minibatch_X, Y:minibatch_Y, Istraining: True})\n",
    "            train_writer.add_summary(summary_str,global_step=i_global)\n",
    "            \n",
    "            g_epoch = i_global/(X_train.shape[0]/minibatch_size)\n",
    "            print (\"\\nCost after epoch(global) %i: %f\" % (g_epoch, minibatch_cost))\n",
    "            saver.save(sess,save_path = save_path,global_step=global_step)\n",
    "            print(\"saved to\",save_path)\n",
    "            print(\"i_global\",i_global)\n",
    "            \n",
    "            graph = tf.get_default_graph()\n",
    "            y_pred = graph.get_tensor_by_name(\"y_pred:0\")\n",
    "            \n",
    "            res = sess.run(y_pred,feed_dict={X:X_test,Istraining: False})\n",
    "            predict_op = tf.argmax(res, 1)\n",
    "            predict_op = (predict_op.eval(session=sess))\n",
    "            correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            val_accuracy = accuracy.eval(feed_dict={X:X_test,Y: Y_finals,Istraining: False},session=sess)\n",
    "            print(\"Validation Accuracy:\", val_accuracy)\n",
    "            \n",
    "        if print_cost == True and epoch % 1 == 0:\n",
    "            costs.append(minibatch_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to restore last checkpoint ...\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_augment/cifar10_cnn_augment-13600\n",
      "Restored checkpoint from: checkpoints_augment/cifar10_cnn_augment-13600\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Trying to restore last checkpoint ...\")\n",
    "\n",
    "    # Use TensorFlow to find the latest checkpoint - if any.\n",
    "    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=save_dir)\n",
    "\n",
    "    # Try and load the data in the checkpoint.\n",
    "    saver.restore(sess, save_path=last_chk_path)\n",
    "\n",
    "    # If we get to this point, the checkpoint was successfully loaded.\n",
    "    print(\"Restored checkpoint from:\", last_chk_path)\n",
    "except:\n",
    "    # If the above failed for some reason, simply\n",
    "    # initialize all the variables for the TensorFlow graph.\n",
    "    print(\"Failed to restore checkpoint. Initializing variables instead.\",sys.exc_info()[0])\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the TF CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................\n",
      "Cost after epoch(global) 1: 0.000729\n",
      "saved to checkpoints_augment/cifar10_cnn_augment\n",
      "i_global 1700\n",
      "Validation Accuracy: 0.4978\n",
      "..............."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-c3d24fa453fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_final_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_final_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-74-aa1d406be40b>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, Y_train, X_validate, Y_validate, learning_rate, num_epochs, minibatch_size, print_cost)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mcurrent_index\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mi_global\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtemp_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mminibatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mminibatch_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIstraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mminibatch_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtemp_cost\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_minibatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model(X_train_final_version, Y_train_final_version,X_validate,Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XeYFeXZx/HvvbsssMAuVXpTQJqIsKJgCYpGjEYsaCDW\nRIOg2PMmmqJ5jeaNsRtFLGAlAqJGbBgVK0VYqnRXkN470uF+/ziDOeI2yuycc/b3ua5z7Tkzzzxz\nD+Xc+8xTxtwdERGRwy0t6gBERCQ1KcGIiEgolGBERCQUSjAiIhIKJRgREQmFEoyIiIRCCUakGGb2\nnpldGXUcIslGCUYSlpl9a2ZnRB2Hu5/t7i9EHQeAmX1iZteUwnnKm9lgM9tkZivM7NZiyt8SlNsU\nHFc+bl8TM/vYzLaa2Zz4v1Mza2tm75vZGjPTpLwUowQjZZqZZUQdwz6JFAvwF6A50Bg4DfidmXUv\nqKCZnQXcDnQLyh8J/G9ckVeAKUAN4I/ACDOrFezbBQwHrj78lyBRU4KRpGRm55rZVDPbYGZjzaxd\n3L7bzewbM9tsZrPM7IK4fVeZ2Rgze9jM1gJ/CbZ9YWYPmNl6M1tgZmfHHfN9q6EEZZua2WfBuT80\nsyfM7OVCrqGrmS0xs9+b2QrgOTOrZmZvm9nqoP63zaxBUP5e4BTgcTPbYmaPB9tbmtkHZrbOzOaa\n2SWH4Y/4SuCv7r7e3WcDzwBXFVF2kLvPdPf1wF/3lTWzFkAH4C533+burwFfARcBuPtcdx8EzDwM\nMUuCUYKRpGNmxwGDgWuJ/Vb8FDAy7rbMN8S+iHOI/Sb9spnVjaviBGA+UBu4N27bXKAm8A9gkJlZ\nISEUVfZfwIQgrr8AlxdzOXWA6sR+8+9D7P/kc8HnRsA24HEAd/8j8DnQ390ru3t/M6sEfBCc9wig\nFzDAzFoXdDIzGxAk5YJe04My1YC6wLS4Q6cBbQq5hjYFlK1tZjWCffPdfXMJ65IUogQjyagP8JS7\nf+nue4L+kR3AiQDu/qq7L3P3ve4+DPga6BR3/DJ3/6e773b3bcG2he7+jLvvAV4g9gVbu5DzF1jW\nzBoBxwN3uvtOd/8CGFnMtewl9tv9juA3/LXu/pq7bw2+lO8FflLE8ecC37r7c8H1TAFeAy4uqLC7\nX+fuVQt57WsFVg5+bow7dCNQpZAYKhdQlqD8/vuKq0tSiBKMJKPGwG3xv30DDYF6AGZ2Rdztsw1A\nW2KtjX0WF1Dnin1v3H1r8LZyAeWKKlsPWBe3rbBzxVvt7tv3fTCzLDN7yswWmtkm4DOgqpmlF3J8\nY+CE/f4sLiXWMjpYW4Kf2XHbsoHNBZTdV37/sgTl999XXF2SQpRgJBktBu7d77fvLHd/xcwaE+sv\n6A/UcPeqwAwg/nZXWKOVlgPVzSwrblvDYo7ZP5bbgKOBE9w9Gzg12G6FlF8MfLrfn0Vld+9X0MnM\nbGDQf1PQayZA0I+yHDg27tBjKbyfZGYBZVe6+9pg35FmVmW//epzKQOUYCTRlTOzCnGvDGIJpK+Z\nnWAxlczsnOBLrBKxL+HVAGb2K2ItmNC5+0Igj9jAgUwz6wz8/ACrqUKs32WDmVUH7tpv/0pio7T2\neRtoYWaXm1m54HW8mbUqJMa+QQIq6BXfL/Ii8Kdg0EFL4DfA84XE/CJwtZm1NrOqwJ/2lXX3ecBU\n4K7g7+8CoB2x23gEf38VgMzgc4W4vjRJckowkujeJfaFu+/1F3fPI/aF9ziwHsgnGLXk7rOAB4Fx\nxL6MjwHGlGK8lwKdgbXAPcAwYv1DJfUIUBFYA4wHRu23/1GgZzDC7LGgn+anxDr3lxG7fXcfcKhf\n0ncRGyyxEPgUuN/dRwGYWaOgxdMIINj+D+BjYFFwTHxi7AXkEvu7+jvQ091XB/saE/t73dei2UZs\nAIWkANMDx0TCY2bDgDnuvn9LRCTlqQUjchgFt6eOMrM0i01M7AH8O+q4RKKQSDOHRVJBHeB1YvNg\nlgD9gqHDImWObpGJiEgodItMRERCUaZvkdWsWdObNGkSdRgiIkll0qRJa9y9VnHlynSCadKkCXl5\neVGHISKSVMxsYUnK6RaZiIiEQglGRERCoQQjIiKhUIIREZFQKMGIiEgolGBERCQUSjAiIhIKJZiD\n8NHslQyfWNyDCkVEyrYyPdHyYLg7//pyEZ/OW03jGlmccGSNqEMSEUlIasEcIDPj4V7taVQji35D\nJrN43dbiDxIRKYOUYA5CdoVyPHtFLrv27OU3L+axdefuqEMSEUk4SjAH6chalfln7+OYt3Izv311\nGnrsgYjIDynBHIKuRx/BHWe34t2vVvDP0flRhyMiklDUyX+IrjmlKbOXb+KhD+ZxdJ0qnNWmTtQh\niYgkBLVgDpGZ8bcLj+HYhlW5ddhU5q7YHHVIIiIJIdQEY2bdzWyumeWb2e0F7C9vZsOC/V+aWZO4\nfXcE2+ea2VnF1Wlmn5vZ1OC1zMz+Hea1xatQLp2nL+9IpfIZXPPiRNZ/t7O0Ti0ikrBCSzBmlg48\nAZwNtAZ6m1nr/YpdDax392bAw8B9wbGtgV5AG6A7MMDM0ouq091Pcff27t4eGAe8Hta1FaR2dgWe\nurwjKzft4Lohk9m1Z29pnl5EJOGE2YLpBOS7+3x33wkMBXrsV6YH8ELwfgTQzcws2D7U3Xe4+wIg\nP6iv2DrNLBs4HSi1Fsw+xzWqxv9dcAzj5q/lnrdnlfbpRUQSSpgJpj4Qv57KkmBbgWXcfTewEahR\nxLElqfN84CN331RQUGbWx8zyzCxv9erVB3RBJXFRxwZcc3JTXhi3kKETFh32+kVEkkUqdvL3Bl4p\nbKe7P+3uue6eW6tWrVACuP3slpzSvCZ/fnMGE79dF8o5REQSXZgJZinQMO5zg2BbgWXMLAPIAdYW\ncWyRdZpZTWK30d45LFdwkDLS03i8dwcaVMui38uTWLphW5ThiIhEIswEMxFobmZNzSyTWKf9yP3K\njASuDN73BEZ7bEr8SKBXMMqsKdAcmFCCOnsCb7v79tCuqoRyssrxzBW57Ni1lz4v5rFt556oQxIR\nKVWhJZigT6U/8D4wGxju7jPN7G4zOy8oNgioYWb5wK3A7cGxM4HhwCxgFHC9u+8prM640/aiiNtj\npa3ZEZV5rPdxzFq+if8ZoeVkRKRssbL8pZebm+t5eXmhn+fJT77hvlFz+J+zjub605qFfj4RkTCZ\n2SR3zy2uXCp28iecvj85kh7t6/HAf+by4ayVUYcjIlIqlGBKgZlx30XtaFsvh5uHTeXrlVpORkRS\nnxJMKalQLp2nr+hIhXLpXPNiHhu2ajkZEUltSjClqG5ORZ66vAPLN2yn/7+msFvLyYhIClOCKWUd\nG1fnnvPb8kX+Gv727pyowxERCY2eBxOBS45vyOwVmxg8ZgGt6lbh4tyGxR8kIpJk1IKJyB9/1oqT\nm9Xkj2/MYNLC9VGHIyJy2CnBRCQjPY3Hf3kcdatW4NqXJrF8o5aTEZHUogQToapZmTxzRS7bdu6m\nz4uT2L5Ly8mISOpQgolYi9pVeKTXccxYtpHfvzZdy8mISMpQgkkAZ7auzW1ntuDNqct46rP5UYcj\nInJYKMEkiOtPa8Y57epy36g5fDxnVdThiIgcMiWYBGFm3N+zHa3rZnPjK1PIX7Ul6pBERA6JEkwC\nycrM4OkrcilfLo0+L+axceuuqEMSETloSjAJpn7Vijx5WUcWr9/KDUOnsGevOv1FJDkpwSSg45tU\n5+4ebfls3mr+/t7sqMMRETkoWiomQfXu1IjZyzfxzOcLaFknm4s6Nog6JBGRA6IWTAL787mt6Xxk\nDe544yumLt4QdTgiIgdECSaBlUtP44lLO3BElfL0eTGPlZu2Rx2SiEiJKcEkuOqVMnn2yly27NhN\nn5e0nIyIJA8lmCTQsk42D13SnmmLN/CH17/ScjIikhSUYJJE97Z1uOWMFrw+ZSnPfr4g6nBERIql\nBJNEbji9GWe3rcP/vTebT+etjjocEZEiKcEkkbQ044GLj6VF7Sr0/9dk5q/WcjIikriUYJJMpfIZ\nPHNFLuXS07jmxTw2bddyMiKSmJRgklDD6lkMuLQDi9Zu5aZXtJyMiCSmUBOMmXU3s7lmlm9mtxew\nv7yZDQv2f2lmTeL23RFsn2tmZxVXp8Xca2bzzGy2md0Y5rVF7cQja3DXeW34eO5q7n9/btThiIj8\nSGhLxZhZOvAEcCawBJhoZiPdfVZcsauB9e7ezMx6AfcBvzCz1kAvoA1QD/jQzFoExxRW51VAQ6Cl\nu+81syPCurZEcfmJjZm9fBMDP/2GVnWr0KN9/ahDEhH5XpgtmE5AvrvPd/edwFCgx35legAvBO9H\nAN3MzILtQ919h7svAPKD+oqqsx9wt7vvBXD3MvHUrr/8vA2dmlbndyOmM32JlpMRkcQRZoKpDyyO\n+7wk2FZgGXffDWwEahRxbFF1HkWs9ZNnZu+ZWfOCgjKzPkGZvNWrk3+ob2ZGGk9e2oGalcvT58VJ\nrNJyMiKSIFKpk788sN3dc4FngMEFFXL3p909191za9WqVaoBhqVG5fI8c0UuG7ftou/Lk9ixW8vJ\niEj0wkwwS4n1iezTINhWYBkzywBygLVFHFtUnUuA14P3bwDtDvkKkkjretk8eMmxTF60gT+9MUPL\nyYhI5MJMMBOB5mbW1MwyiXXaj9yvzEjgyuB9T2C0x74ZRwK9glFmTYHmwIRi6vw3cFrw/ifAvJCu\nK2H97Ji63Hh6M16dtITnxnwbdTgiUsaFNorM3XebWX/gfSAdGOzuM83sbiDP3UcCg4CXzCwfWEcs\nYRCUGw7MAnYD17v7HoCC6gxO+XdgiJndAmwBrgnr2hLZzWe0YM6Kzdz77mxa1K7Cyc1rRh2SiJRR\nVpZvpeTm5npeXl7UYRx2W3bs5sIBY1i5aQdvXn8STWpWijokEUkhZjYp6O8uUip18kugcvkMnr3i\neMzgNy/msVnLyYhIBJRgUlSjGlkM+GUH5q/5jluGTdVyMiJS6pRgUliXZjW589zWfDh7FdcPmcy2\nnRq+LCKlRwkmxV3ZpQl/OqcV789aQe9nxrNmy46oQxKRMkIJpgy45pQjefLSjsxZsYkLBowhf5We\nIyMi4VOCKSO6t63D0D6d2bZzDxcOGMO4b9ZGHZKIpDglmDKkfcOqvHHdSRyRXYErBn/J65OXRB2S\niKQwJZgypmH1LF7r14Xjm1Tn1uHTeOTDeVpWRkRCoQRTBuVULMfzv+rERR0a8MiHX3Pbq9PYuXtv\n1GGJSIoJbakYSWyZGWk8cHE7GtfI4qEP5rF8w3YGXtaRnKxyUYcmIilCLZgyzMy4sVtzHv7FsUxa\nuJ4LnxzD4nVbow5LRFKEEoxwwXENePHqTqzZspMLBoxhyqL1UYckIilACUYAOPHIGrx+XReyMjPo\n9fR4Rs1YHnVIIpLklGDke0fVqswb13Whdb1s+g2ZzLOfz9cIMxE5aEow8gM1Kpfnld+cSPc2dbjn\nndnc+eZMdu/RCDMROXBKMPIjFcql88QvO3DtqUfy0viF9HlpEt/t2B11WCKSZJRgpEBpacYdP2vF\nPee35dN5q7nkqXGs3LQ96rBEJIkowUiRLjuxMc9emcu3a77j/CfGMHv5pqhDEpEkoQQjxTrt6CN4\ntW8X3OHigeP4dN7qqEMSkSSgBCMl0rpeNm9c34WG1bP49fMT+deXi6IOSUQSnBKMlFjdnIq82rcz\nJzeryR/e+Iq/vzeHvXoUs4gUQglGDkjl8hkMujKXS09oxMBPv+GGoVPYvkuPYhaRH9Nil3LAMtLT\nuOf8tjSukcXf3p3Dio3befryjtSoXD7q0EQkgagFIwfFzOhz6lEMuLQDM5Zu5MInxzJ/tR7FLCL/\npQQjh+Rnx9TllT4nsmX7bi58ciwTFqyLOiQRSRBKMHLIOjSqxhvXnUT1Splc9uyXvDl1adQhiUgC\nCDXBmFl3M5trZvlmdnsB+8ub2bBg/5dm1iRu3x3B9rlmdlZxdZrZ82a2wMymBq/2YV6b/FCjGlm8\n3q8L7RtV5aahU3l89NdaKFOkjAstwZhZOvAEcDbQGuhtZq33K3Y1sN7dmwEPA/cFx7YGegFtgO7A\nADNLL0Gd/+Pu7YPX1LCuTQpWNSuTl67uxAXH1eeB/8zj969NZ5cWyhQps8JswXQC8t19vrvvBIYC\nPfYr0wN4IXg/AuhmZhZsH+ruO9x9AZAf1FeSOiVC5TPSeeiSY7mxW3OG5y3hqucmsHHbrqjDEpEI\nhJlg6gOL4z4vCbYVWMbddwMbgRpFHFtcnfea2XQze9jMChwza2Z9zCzPzPJWr9aSJ2EwM249swUP\nXHwsX85fx8UDx7JkvR7FLFLWpFIn/x1AS+B4oDrw+4IKufvT7p7r7rm1atUqzfjKnJ4dG/Dirzux\nfON2LhgwlulLNkQdkoiUojATzFKgYdznBsG2AsuYWQaQA6wt4thC63T35R6zA3iO2O00iViXZjV5\nvV8XMtPT+MVT4/lg1sqoQxKRUhJmgpkINDezpmaWSazTfuR+ZUYCVwbvewKjPTb0aCTQKxhl1hRo\nDkwoqk4zqxv8NOB8YEaI1yYHoHntKrxxfRda1K5Mn5fyeG7MgqhDEpFSENpSMe6+28z6A+8D6cBg\nd59pZncDee4+EhgEvGRm+cA6YgmDoNxwYBawG7je3fcAFFRncMohZlYLMGAq0Desa5MDd0SVCgzt\n05mbhk7hf9+axaJ1W/nTOa1JT7OoQxORkFhZnquQm5vreXl5UYdRpuzZ6/zt3dkM+mIBZ7SqzWO9\n25OVqSXxRJKJmU1y99ziyqVSJ78kgfQ048/ntubuHm0YPWclv3hqPKs261HMIqlICUYicUXnJjxz\nRS75q7ZwwRNjmbdyc9QhichhpgQjkenWqjav9u3Mrj17uWjAWL74ek3UIYnIYaQEI5FqWz+HN64/\nifrVKnLVcxMYnre4+INEJCmod1UiV79q7FHM1w2ZzO9GTOfTeavJbVyNNvVyaF0vm8rl9c9UJBmV\n6H+umV3s7q8Wt03kYFWpUI7BVx3P/707h5HTlvLO9OXf72tasxKt62XTpl42berl0KZeNjX19EyR\nhFeiYcpmNtndOxS3LdlomHJicndWbd7BzGUbmbl0EzOXbWLGso0sWb/t+zJ1sisECSeb1vVyaFs/\nm/pVKxKbZysiYSrpMOUiWzBmdjbwM6C+mT0Wtyub2ARIkcPOzKidXYHa2RU4vWXt77dv3LqLmcs3\nMmtZkHSWbuTjuavYG/yOlFOx3PdJp239WEunac3KmswpEpHibpEtA/KA84BJcds3A7eEFZRIQXKy\nytHlqJp0Oarm99u27dzDnBWxhDNz2UZmLtvEC+MWsnN37Dk0Fcul07JulVjSqZdDm3o5tKhTmfIZ\n6VFdhkiZUdJbZOXcfVfwvhrQ0N2nhx1c2HSLLDXt2rOXb1ZvYcbS/yad2cs2sXlHrNGdkWY0O6Iy\nbYJba23q5dCqbhWqVCgXceQiyaGkt8hKmmA+IdaKySDWklkFjHX3pG7FKMGUHXv3OovXb/1B0pm5\nbCNrtuz8vkyTGlmxQQT1NZhApCiHpQ8mTo67bzKza4AX3f0uM0v6FoyUHWlpRuMalWhcoxLntKsL\nFDyYYNqSDbzz1X9HsNXOLh/cWosNJmhTL5sG1TSYQKQkSppgMoLl8C8B/hhiPCKlpiSDCWYsjbV2\nChtM0LpeNo1rVKJhtSxqVs5U4hGJU9IEczexJfLHuPtEMzsS+Dq8sESiU9RgghnLNjGrgMEEEBtQ\n0KBaRRpWz6Lhvp/Vs2hYLYuG1Suqj0fKHC3Xrz4YOUi79uzl2zXfsWjdVhat28riddtYvH4ri9dt\nZcn6bWzZ8cOR/FWzyn2fbBpWy6JBkIgaVc+ifrWKGtkmSeOw9sGYWQPgn8BJwabPgZvcfcnBhyiS\n3Mqlp9G8dhWa167yo33uzoatu4KE89/Es2jdVmYv38yHs1axc89/Wz9mULtKhR8ln32toDrZFTSf\nR5JOSW+RPQf8C7g4+HxZsO3MMIISSXZmRrVKmVSrlEm7BlV/tH/vXmfl5u2x5LNu6w8S0fj5a1k+\ndSnxNxfKpRv1q8YSToO4VtC+23HVK6n/RxJPSRNMLXd/Lu7z82Z2cxgBiZQFaWlG3ZyK1M2pSKem\n1X+0f8fuPSzbsP1HyWfJuq28v2wF677b+YPylTLTC04+wftKWjBUIlDSf3Vrzewy4JXgc29gbTgh\niUj5jHSa1qxE05qVCty/ZcdulqzfyqK1W1m8flvQ7xO7DTf2mzVs3bnnB+WrV8qkYbWKnNqiFtf+\n5CitUC2loqQTLRsT64PpDDgwFrjB3ZP64R3q5JdU5O6s+27n94lnX//PgjXfMX7+OmpWLs/vzjqa\nnh0bkKZ+HTkIh3sm/wvAze6+PvhcHXjA3X99yJFGSAlGypqpizdw91szmbxoA23rZ3PnuW0KvEUn\nUpSSJpiSPtGy3b7kAuDu64DjDjY4EYlG+4ZVea1fFx7t1Z51W3ZyyVPjuH7IZBav2xp1aJKCSppg\n0oJFLoHvWzC6iSuShMyMHu3r89FtXbnljBaMnrOKbg99yv3vz/nR3B2RQ1HSBPMgMM7M/mpmfyXW\nB/OP8MISkbBVzEznpjOaM/q3P+GcY+ryxMffcNoDn/Bq3mL27i27E7Dl8CnxTH4zaw2cHnwc7e6z\nQouqlKgPRuS/pixaz91vz2LKog0cUz+HO3/emuObqH9GfuywdvKnKiUYkR9yd0ZOW8bf35vD8o3b\nOaddXW7v3pKG1bOiDk0SyOHu5D/YILqb2Vwzyzez2wvYX97MhgX7vzSzJnH77gi2zzWzsw6gzsfM\nbEtY1ySSyvb1z4y+rSs3n9Gcj2avpNtDn/LA+3P5Tv0zcoBCSzBmlg48AZwNtAZ6B7fZ4l0NrHf3\nZsDDwH3Bsa2BXkAboDswwMzSi6vTzHKBaojIIamYmc7NZ7Tg49925Wdt6/D4x/mc9sAnjJi0RP0z\nUmJhtmA6AfnuPt/ddwJDgR77lekBvBC8HwF0s9iCSj2Aoe6+w90XAPlBfYXWGSSf+4HfhXhNImVK\n3ZyKPNLrOF6/rgv1qlbkt69O4/wBY8j7dl3UoUkSCDPB1AfiZ/ovCbYVWMbddwMbgRpFHFtUnf2B\nke6+nCKYWR8zyzOzvNWrVx/QBYmUVR0aVeP1fl145BftWbVpBz0HjuOGV6awZL3mz0jhQu2DKS1m\nVo/YSs//LK6suz/t7rnunlurVq3wgxNJEWlpxvnH1Wf0b3/CTd2a88GsFXR78FMe/I/6Z6RgYSaY\npUDDuM8Ngm0FljGzDCCH2CKahR1b2PbjgGZAvpl9C2SZWf7huhAR+a+szAxuObMFo2/rSve2dfjn\n6HxOf/ATXlP/jOwnzAQzEWhuZk3NLJNYp/3I/cqMBK4M3vckNr/Gg+29glFmTYHmwITC6nT3d9y9\njrs3cfcmwNZg4ICIhKRe1Yo82us4XuvXhTo5Fbnt1WlcMGAMkxaqf0ZiQkswQZ9Kf+B9YDYw3N1n\nmtndZnZeUGwQUCNobdwK3B4cOxMYDswCRgHXu/uewuoM6xpEpHgdG1fjjX5deOiSY1mxaTsXPTmO\nG1+ZwtIN26IOTSKmiZaaaCly2GzduZuBn87nqU+/AeDaU4+kb9ejyMrU0oWpJCEmWopI2ZKVmcGt\nZ7Zg9G+7clabOjw2OjZ/5vXJ6p8pi5RgROSwq1+1Io/1Po7X+nWmTnYFbh0+jQueHMukheuLP1hS\nhhKMiISmY+PqvHHdSTx48bEs37CNi54cy01Dp7BM/TNlghKMiIQqLc24qGMDPv5tV244vRmjZqzg\n9Ac/4aEP5rF1p+bPpDIlGBEpFZXKZ3DbT4/mo9t+whmtavPYR19z+gOf8u8pS9U/k6KUYESkVDWo\nlsXjv+zAiL6dqVWlPDcPm8qFT45l8iL1z6QaJRgRiURuk+q8ef1JPHDxsSzbsI0LB4zlZvXPpBQl\nGBGJTFqa0TPon+l/WjPeDfpnHvlwHtt27ok6PDlESjAiErlK5TP47VlH89GtP6Fbq9o88uHXnP7g\nJ3w8d1XUockhUIIRkYTRsHoWT/yyA6/27UyVChn86rmJ/H7EdDZv3xV1aHIQlGBEJOEc36Q6b91w\nMv26HsWrkxbT/ZHPGZO/Juqw5AApwYhIQiqfkc7vu7dkRL8ulM9I49Jnv+TON2do7kwSUYIRkYTW\noVE13rnxFK4+uSkvjV/I2Y9+zkQ9sjkpKMGISMKrmJnOn89tzdDfnMhedy55ahz3vD2L7bs00iyR\nKcGISNI44cgajLrpVC49oRHPfrGAcx77nCmaoJmwlGBEJKlUKp/BPecfw8tXn8C2nXu46Mmx/GPU\nHHbsVmsm0SjBiEhSOrl5TUbdcio9OzZgwCff0OPxMcxYujHqsCSOEoyIJK3sCuX4R89jGXxVLmu/\n28n5T4zhkQ/nsWvP3qhDE5RgRCQFnN6yNh/ccirntKvLIx9+zQUDxjBv5eaowyrzlGBEJCVUzcrk\n0V7HMfCyDizfsJ1zH/uCJz/5hj16FEBklGBEJKV0b1uX/9xyKt1aHcF9o+bQc+BY5q/eEnVYZZIS\njIiknBqVyzPg0g482qs981d/x9mPfs6gLxbowWalTAlGRFKSmdGjfX0+uOVUTm5Wk7++PYtez4xn\n0dqtUYdWZijBiEhKOyK7As9emcs/erZj9rJNdH/0M14evxB3tWbCpgQjIinPzLgktyHv33IqHRtX\n40//nsEVgyfo6ZkhU4IRkTKjXtWKvPjrTtxzflsmLVzPWQ9/xvC8xWrNhCTUBGNm3c1srpnlm9nt\nBewvb2bDgv1fmlmTuH13BNvnmtlZxdVpZoPMbJqZTTezEWZWOcxrE5HkZGZcdmJjRt10Kq3qZfO7\nEdO55oU8Vm3aHnVoKSe0BGNm6cATwNlAa6C3mbXer9jVwHp3bwY8DNwXHNsa6AW0AboDA8wsvZg6\nb3H3Y929HbAI6B/WtYlI8mtUI4uhvzmRO89tzRf5azjz4c94c+pStWYOozBbMJ2AfHef7+47gaFA\nj/3K9ACBrNYOAAAQKklEQVReCN6PALqZmQXbh7r7DndfAOQH9RVap7tvAgiOrwjoX4mIFCktzfj1\nyU1596ZTOLJWJW4aOpV+L09mzZYdUYeWEsJMMPWBxXGflwTbCizj7ruBjUCNIo4tsk4zew5YAbQE\n/llQUGbWx8zyzCxv9erVB35VIpJyjqpVmRF9u/D77i0ZPWcVZz38Ge99tTzqsJJeSnXyu/uvgHrA\nbOAXhZR52t1z3T23Vq1apRqfiCSu9DSjX9ejeOuGk6lbtQL9hkzmpqFT2LB1Z9ShJa0wE8xSoGHc\n5wbBtgLLmFkGkAOsLeLYYut09z3Ebp1ddMhXICJlztF1qvDGdSdxyxkteGf6cn768GeMnrMy6rCS\nUpgJZiLQ3MyamlkmsU77kfuVGQlcGbzvCYz2WA/bSKBXMMqsKdAcmFBYnRbTDL7vgzkPmBPitYlI\nCiuXnsZNZzTn39efRPVKmfz6+Tz+59VpbNq+K+rQkkpGWBW7+24z6w+8D6QDg919ppndDeS5+0hg\nEPCSmeUD64glDIJyw4FZwG7g+qBlQiF1pgEvmFk2YMA0oF9Y1yYiZUPb+jm82f8kHvvoa5785BvG\n5K/hvp7tOKW5bq+XhJXlIXm5ubmel5cXdRgikgSmLFrPba9OY/7q77j0hEb84WetqFQ+tN/RE5qZ\nTXL33OLKpVQnv4hIWI5rVI13bzyFa05uyr8mLKL7o58xfv7aqMNKaEowIiIlVKFcOn86tzXD+nQm\nzYzez4zn7rdmsW3nnqhDS0hKMCIiB6hT0+q8d9MpXH5iYwaPWcA5j33OtMUbog4r4SjBiIgchKzM\nDO7u0ZYh15zAjt17ueSpcbw/c0XUYSUUJRgRkUNwUrOajOx/Ei3rZtPv5Um8NH5h1CElDCUYEZFD\nVKNyeV75zQl0PfoI/vzvGfxj1BwtmokSjIjIYZGVmcHTl3ekd6eGDPjkG257dRo7d++NOqxIlc1B\n3CIiIchIT+NvFxxD3ZyKPPTBPFZv3sGTl3WkchmdL6MWjIjIYWRm3NitOf+4qB1jv1nLJQPHldmH\nmSnBiIiE4JLjG/LslbksWPMdFwwYS/6qLVGHVOqUYEREQnLa0Ucw7NoT2bF7Dz0HjiXv23VRh1Sq\nlGBERELUrkFVXu93EtWyMrn02S8ZNaPszJVRghERCVmjGlmM6NuZVnWz6TdkEi+M/TbqkEqFEoyI\nSCmIzZU5kW4tj+CukTP5+3tz2Ls3tefKKMGIiJSSipnpDLysI788oREDP039uTJlc3C2iEhEMtLT\nuPf8ttTLqcAD/9k3V6YDVSqUizq0w04tGBGRUmZm9D+9Off3bMf4+Wu55KnxrEzBuTJKMCIiEbk4\ntyGDrjqehWu/48IBY8lftTnqkA4rJRgRkQj9pEUthvXpzI7de7noyXFMTKG5MkowIiIRO6ZBDm9c\n14UalWJzZd77annUIR0WSjAiIgmgYfUsRvTrQtt62Vz3r8k8P2ZB1CEdMiUYEZEEUb1SJkOuOZEz\nWtXmL2/N4v/enZ3Uc2WUYEREEsi+uTKXndiIpz6bz83DprJj956owzoomgcjIpJg0tOMv/ZoS92c\nitz//lzWbNnBwMs7kp1kc2XUghERSUBmxvWnNePBi49lwoJ1XDJwHCs2JtdcmVATjJl1N7O5ZpZv\nZrcXsL+8mQ0L9n9pZk3i9t0RbJ9rZmcVV6eZDQm2zzCzwWaWXKleRKQAF3VswOCrjmfxuq1cOGAM\n81Ymz1yZ0BKMmaUDTwBnA62B3mbWer9iVwPr3b0Z8DBwX3Bsa6AX0AboDgwws/Ri6hwCtASOASoC\n14R1bSIipenUFrUYdm1ndu11ej45li/nr406pBIJswXTCch39/nuvhMYCvTYr0wP4IXg/Qigm5lZ\nsH2ou+9w9wVAflBfoXW6+7seACYADUK8NhGRUtW2fg6v9+tCzSrluXzQBN6ZnvhzZcJMMPWBxXGf\nlwTbCizj7ruBjUCNIo4tts7g1tjlwKhDvgIRkQTSsHoWr/XtwjENcuj/ymQGfZHYc2VSsZN/APCZ\nu39e0E4z62NmeWaWt3r16lIOTUTk0FSrlMmQa07gp61r89e3Z3HvO7MSdq5MmAlmKdAw7nODYFuB\nZcwsA8gB1hZxbJF1mtldQC3g1sKCcven3T3X3XNr1ap1gJckIhK9CuXSGXBpR67o3JhnPl/ATQk6\nVybMBDMRaG5mTc0sk1in/cj9yowErgze9wRGB30oI4FewSizpkBzYv0qhdZpZtcAZwG93T11n+Aj\nIkJsrsz/nteG33dvyVvTlnHl4Als3LYr6rB+ILQEE/Sp9AfeB2YDw919ppndbWbnBcUGATXMLJ9Y\nq+P24NiZwHBgFrG+lOvdfU9hdQZ1DQRqA+PMbKqZ3RnWtYmIJAIzo1/Xo3jkF+2ZtHA9lwwcx/KN\n26IO63sWazCUTbm5uZ6Xlxd1GCIih+yLr9fQ9+VJVKmQwfO/6sTRdaqEdi4zm+TuucWVS8VOfhGR\nMufk5jUZdu2J7Nnr9Bw4lnHfRD9XRglGRCRFtKmXw+vXdaF2dgWuHDyBt6YtizQeJRgRkRTSoFoW\nI/p25tiGOdzwyhSe/Xx+ZLEowYiIpJiqWZm8dPUJnN22Dve8M5u734pmrowSjIhICqpQLp3Hf9mB\nq7o0YfCYBdwwdArbd5XuXBk9D0ZEJEWlpxl3/bw19apW4G/vzmH15h08c3kuOVmls9i8WjAiIinM\nzOhz6lE82qs9Uxatp+fAsSzbUDpzZZRgRETKgB7t6/PCrzqxYuN2LhgwhvxVW0I/pxKMiEgZ0aVZ\nTYb37UyL2lWoVaV86OdTH4yISBnSqm42L119QqmcSy0YEREJhRKMiIiEQglGRERCoQQjIiKhUIIR\nEZFQKMGIiEgolGBERCQUSjAiIhKKMv3IZDNbDSw8yMNrAmsOYzhhS6Z4FWt4kineZIoVkiveQ421\nsbvXKq5QmU4wh8LM8kryTOpEkUzxKtbwJFO8yRQrJFe8pRWrbpGJiEgolGBERCQUSjAH7+moAzhA\nyRSvYg1PMsWbTLFCcsVbKrGqD0ZEREKhFoyIiIRCCUZEREKhBHMQzKy7mc01s3wzuz3qeApjZoPN\nbJWZzYg6lpIws4Zm9rGZzTKzmWZ2U9QxFcbMKpjZBDObFsT6v1HHVBwzSzezKWb2dtSxFMfMvjWz\nr8xsqpnlRR1PUcysqpmNMLM5ZjbbzDpHHVNhzOzo4M9032uTmd0c2vnUB3NgzCwdmAecCSwBJgK9\n3X1WpIEVwMxOBbYAL7p726jjKY6Z1QXquvtkM6sCTALOT9A/WwMqufsWMysHfAHc5O7jIw6tUGZ2\nK5ALZLv7uVHHUxQz+xbIdfeEn7hoZi8An7v7s2aWCWS5+4ao4ypO8F22FDjB3Q92wnmR1II5cJ2A\nfHef7+47gaFAj4hjKpC7fwasizqOknL35e4+OXi/GZgN1I82qoJ5zJbgY7nglbC/rZlZA+Ac4Nmo\nY0klZpYDnAoMAnD3ncmQXALdgG/CSi6gBHMw6gOL4z4vIUG/BJOZmTUBjgO+jDaSwgW3nKYCq4AP\n3D1hYwUeAX4H7I06kBJy4D9mNsnM+kQdTBGaAquB54Lbj8+aWaWogyqhXsArYZ5ACUYSjplVBl4D\nbnb3TVHHUxh33+Pu7YEGQCczS8jbkGZ2LrDK3SdFHcsBONndOwBnA9cHt3sTUQbQAXjS3Y8DvgMS\ntl92n+BW3nnAq2GeRwnmwC0FGsZ9bhBsk8Mg6M94DRji7q9HHU9JBLdEPga6Rx1LIU4Czgv6NYYC\np5vZy9GGVDR3Xxr8XAW8QezWdCJaAiyJa72OIJZwEt3ZwGR3XxnmSZRgDtxEoLmZNQ1+C+gFjIw4\nppQQdJwPAma7+0NRx1MUM6tlZlWD9xWJDfqYE21UBXP3O9y9gbs3IfbvdbS7XxZxWIUys0rBIA+C\n200/BRJyJKS7rwAWm9nRwaZuQMINSilAb0K+PQax5p0cAHffbWb9gfeBdGCwu8+MOKwCmdkrQFeg\nppktAe5y90HRRlWkk4DLga+Cvg2AP7j7uxHGVJi6wAvBSJw0YLi7J/zw3yRRG3gj9vsGGcC/3H1U\ntCEV6QZgSPAL53zgVxHHU6QgaZ8JXBv6uTRMWUREwqBbZCIiEgolGBERCYUSjIiIhEIJRkREQqEE\nIyIioVCCkZRjZmODn03M7JeHue4/FHSusJjZ+WZ2Z0h1/6H4Ugdc5zFm9vzhrleSk4YpS8oys67A\nbw9k5WAzy3D33UXs3+LulQ9HfCWMZyxw3qGuKlzQdYV1LWb2IfBrd190uOuW5KIWjKQcM9u3yvHf\ngVOC517cEixOeb+ZTTSz6WZ2bVC+q5l9bmYjCWZhm9m/g4UWZ+5bbNHM/g5UDOobEn8ui7nfzGYE\nzzH5RVzdn8Q9L2RIsGIBZvZ3iz37ZrqZPVDAdbQAduxLLmb2vJkNNLM8M5sXrDG2b9HNEl1XXN0F\nXctlFnvGzVQzeyqYRIqZbTGzey327JvxZlY72H5xcL3TzOyzuOrfIrZigJR17q6XXin1ArYEP7sC\nb8dt7wP8KXhfHsgjthpuV2KLFDaNK1s9+FmR2DIlNeLrLuBcFwEfEFvdoTawiNhs/67ARmJr1qUB\n44CTgRrAXP57F6FqAdfxK+DBuM/PA6OCepoTWwerwoFcV0GxB+9bEUsM5YLPA4ArgvcO/Dx4/4+4\nc30F1N8/fmIrMrwV9b8DvaJ/aakYKUt+CrQzs57B5xxiX9Q7gQnuviCu7I1mdkHwvmFQbm0RdZ8M\nvOLue4CVZvYpcDywKah7CUCwBE4TYDywHRhksSdMFrTMTF1iS8HHG+7ue4GvzWw+0PIAr6sw3YCO\nwMSggVWR2GMICOrZF98kYsuMAIwBnjez4UD8wqSrgHolOKekOCUYKUsMuMHd3//BxlhfzXf7fT4D\n6OzuW83sE2IthYO1I+79HiDDY2vadSL2xd4T6A+cvt9x24gli3j7d5o6JbyuYhjwgrvfUcC+Xe6+\n77x7CL433L2vmZ1A7EFmk8yso7uvJfZnta2E55UUpj4YSWWbgSpxn98H+gWPBMDMWljBD4fKAdYH\nyaUlcGLcvl37jt/P58Avgv6QWsSecjihsMAs9sybHI8t5HkLcGwBxWYDzfbbdrGZpZnZUcCRxG6z\nlfS69hd/LR8BPc3siKCO6mbWuKiDzewod//S3e8k1tLa9xiLFiTo6sdSutSCkVQ2HdhjZtOI9V88\nSuz21OSgo301cH4Bx40C+prZbGJf4OPj9j0NTDezye5+adz2N4DOwDRirYrfufuKIEEVpArwpplV\nINZ6uLWAMp8BD5qZxbUgFhFLXNlAX3ffbmbPlvC69veDazGzPxF7imQasAu4Hijqcbr3m1nzIP6P\ngmsHOA14pwTnlxSnYcoiCczMHiXWYf5hML/kbXcfEXFYhTKz8sCnxJ5IWehwbykbdItMJLH9DciK\nOogD0Ai4XclFQC0YEREJiVowIiISCiUYEREJhRKMiIiEQglGRERCoQQjIiKh+H8W4BP5zdleqgAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd6c7ffa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the cost\n",
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.title(\"Learning rate =\" + str(0.001))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Testing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and final csv generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints_augment/cifar10_cnn_augment-13600\n",
      "Restored checkpoint from: checkpoints_augment/cifar10_cnn_augment-13600\n"
     ]
    }
   ],
   "source": [
    "# Use TensorFlow to find the latest checkpoint - if any.\n",
    "last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=save_dir)\n",
    "\n",
    "# Try and load the data in the checkpoint.\n",
    "saver.restore(sess, save_path=last_chk_path)\n",
    "\n",
    "# If we get to this point, the checkpoint was successfully loaded.\n",
    "print(\"Restored checkpoint from:\", last_chk_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7418"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints_augment/cifar10_cnn_augment-88400\n",
      "Restored checkpoint from: checkpoints_augment/cifar10_cnn_augment-88400\n"
     ]
    }
   ],
   "source": [
    "# Use TensorFlow to find the latest checkpoint - if any.\n",
    "last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=save_dir)\n",
    "\n",
    "# Try and load the data in the checkpoint.\n",
    "saver.restore(sess, save_path=last_chk_path)\n",
    "\n",
    "# If we get to this point, the checkpoint was successfully loaded.\n",
    "print(\"Restored checkpoint from:\", last_chk_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "y_pred = graph.get_tensor_by_name(\"y_pred:0\")\n",
    "\n",
    "feed_dict_testing = {X: X_test,Istraining: False}\n",
    "\n",
    "result=sess.run(y_pred, feed_dict=feed_dict_testing)\n",
    "\n",
    "predict_op = tf.argmax(result, 1)\n",
    "\n",
    "final_list= predict_op.eval(session=sess)\n",
    "\n",
    "s= \"\"\n",
    "s = s+\"id,label\\n\"\n",
    "for i in range(1,5001):\n",
    "    s=s+str(str(i-1)+\",\"+labels[final_list[i-1]]+\"\\n\")\n",
    "\n",
    "f = open('Final_Submission.csv','w')\n",
    "f.write(s)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
